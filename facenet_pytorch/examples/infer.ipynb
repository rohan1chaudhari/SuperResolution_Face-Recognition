{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection and recognition inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rohan/cv/repo/facenet_pytorch/examples\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from utils.detect_face import extract_face\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "Face Detection model from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inception Resnet V1 module\n",
    "\n",
    "Inception Resnet to get embeddings of each face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a dataset and data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('../../data/sr_img/')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfom MTCNN facial detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    boxes, prob = mtcnn.detect(x)\n",
    "    \n",
    "    for idx, box in enumerate(boxes):\n",
    "        face = extract_face(x, box, 160, 0, f\"../../data/faces/face{idx}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manual segregation into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder('../../data/face_folder')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detected with probability: 0.999467\n",
      "Face detected with probability: 0.999893\n",
      "Face detected with probability: 0.999949\n",
      "Face detected with probability: 0.999420\n",
      "Face detected with probability: 1.000000\n",
      "Face detected with probability: 0.999997\n",
      "Face detected with probability: 0.999999\n",
      "Face detected with probability: 0.995827\n",
      "Face detected with probability: 0.999962\n",
      "Face detected with probability: 0.999832\n",
      "Face detected with probability: 0.999917\n",
      "Face detected with probability: 0.999829\n"
     ]
    }
   ],
   "source": [
    "aligned = []\n",
    "names = []\n",
    "for x, y in loader:\n",
    "    x_aligned, prob = mtcnn(x, return_prob=True)\n",
    "    if x_aligned is not None:\n",
    "        print('Face detected with probability: {:8f}'.format(prob))\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the faces to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, a in enumerate(aligned[:]):\n",
    "#     plt.imshow(a.cpu().numpy().transpose(1, 2, 0))\n",
    "    final_face = a.cpu().numpy().transpose(1, 2, 0)[:,:, [2, 1, 0]]\n",
    "    cv2.imwrite(f\"../../data/faces/face{idx}.jpg\", (final_face)*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print distance matrix for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohan/cv/super-resolution/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "df = pd.DataFrame(dists, columns=names, index=names)\n",
    "print(df[df[\"mbappe_real_image\"] > 0][\"mbappe_real_image\"].argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      face1    face10    face11     face2     face3     face4  \\\n",
      "face1              0.000000  1.541790  1.254309  1.311747  1.153131  1.076305   \n",
      "face10             1.541790  0.000000  1.469768  1.272414  1.415111  1.450225   \n",
      "face11             1.254309  1.469768  0.000000  1.382727  1.420647  1.491348   \n",
      "face2              1.311747  1.272414  1.382727  0.000000  1.300457  1.174065   \n",
      "face3              1.153131  1.415111  1.420647  1.300457  0.000000  1.029869   \n",
      "face4              1.076305  1.450225  1.491348  1.174065  1.029869  0.000000   \n",
      "face5              1.437752  1.285775  1.433558  1.226325  1.428909  1.165871   \n",
      "face6              1.360260  1.427959  1.313521  1.275958  1.499547  1.376816   \n",
      "face7              1.450648  1.481493  1.407792  1.468432  1.221348  1.331831   \n",
      "face8              1.362209  1.191827  0.899785  1.442619  1.439378  1.508914   \n",
      "face9              1.201638  1.487277  1.440368  1.240009  1.236576  1.243151   \n",
      "mbappe_real_image  0.516229  1.572129  1.216542  1.305156  1.217318  1.024976   \n",
      "\n",
      "                      face5     face6     face7     face8     face9  \\\n",
      "face1              1.437752  1.360260  1.450648  1.362209  1.201638   \n",
      "face10             1.285775  1.427959  1.481493  1.191827  1.487277   \n",
      "face11             1.433558  1.313521  1.407792  0.899785  1.440368   \n",
      "face2              1.226325  1.275958  1.468432  1.442619  1.240009   \n",
      "face3              1.428909  1.499547  1.221348  1.439378  1.236576   \n",
      "face4              1.165871  1.376816  1.331831  1.508914  1.243151   \n",
      "face5              0.000000  1.456971  1.475499  1.328180  1.386314   \n",
      "face6              1.456971  0.000000  1.513614  1.487392  1.511638   \n",
      "face7              1.475499  1.513614  0.000000  1.340575  1.111930   \n",
      "face8              1.328180  1.487392  1.340575  0.000000  1.480270   \n",
      "face9              1.386314  1.511638  1.111930  1.480270  0.000000   \n",
      "mbappe_real_image  1.406289  1.289836  1.516957  1.363654  1.388478   \n",
      "\n",
      "                   mbappe_real_image  \n",
      "face1                       0.516229  \n",
      "face10                      1.572129  \n",
      "face11                      1.216542  \n",
      "face2                       1.305156  \n",
      "face3                       1.217318  \n",
      "face4                       1.024976  \n",
      "face5                       1.406289  \n",
      "face6                       1.289836  \n",
      "face7                       1.516957  \n",
      "face8                       1.363654  \n",
      "face9                       1.388478  \n",
      "mbappe_real_image           0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
